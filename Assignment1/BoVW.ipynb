{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(x, k, no_of_iterations):\n",
    "    idx = np.random.choice(len(x), k, replace=False)\n",
    "    print(idx)\n",
    "    #Randomly choosing Centroids \n",
    "    centroids = x[idx, :] #Step 1\n",
    "     \n",
    "    #finding the distance between centroids and all the data points\n",
    "    distances = cdist(x, centroids ,'euclidean') #Step 2\n",
    "     \n",
    "    #Centroid with the minimum Distance\n",
    "    points = np.array([np.argmin(i) for i in distances]) #Step 3\n",
    "    \n",
    "    for i in range(k):\n",
    "        points[idx[i]] = i\n",
    "        \n",
    "    \n",
    "    #Repeating the above steps for a defined number of iterations\n",
    "    for itr in range(no_of_iterations): \n",
    "        centroids = []\n",
    "        print(f\"*** Iteration {itr} ***\")\n",
    "        for idx in range(k):\n",
    "            #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            print(x[points==idx])\n",
    "            temp_cent = x[points==idx].mean(axis=0) \n",
    "            centroids.append(temp_cent)\n",
    " \n",
    "        centroids = np.vstack(centroids) #Updated Centroids \n",
    "         \n",
    "        distances = cdist(x, centroids ,'euclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "         \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padImageForPatches(img, patch_shape):\n",
    "    return cv2.copyMakeBorder(src=img, left=0, right=patch_shape[1]*((img.shape[1]+31)//patch_shape[1])-img.shape[1], top=0, bottom=patch_shape[0]*((img.shape[0]+31)//patch_shape[0])-img.shape[0], borderType=cv2.BORDER_REFLECT)\n",
    "\n",
    "def divideIntoPatches(img, patch_shape):\n",
    "    img = padImageForPatches(img, patch_shape)\n",
    "    img_shape = img.shape\n",
    "    patch_array = np.empty((int((img_shape[0]*img_shape[1])/(patch_shape[0]*patch_shape[1])), patch_shape[0], patch_shape[1], 3), dtype=np.int32)\n",
    "    for i in range(0, int(img_shape[0]/patch_shape[0])):\n",
    "        for j in range(0, int(img_shape[1]/patch_shape[1])):\n",
    "            patch_array[i*int(img_shape[1]/patch_shape[1]) + j] = img[i*patch_shape[0]:i*patch_shape[0]+patch_shape[0], j*patch_shape[1]:j*patch_shape[1]+patch_shape[1], :]\n",
    "\n",
    "    return patch_array\n",
    "\n",
    "def getColorHistFeatures(img, n_bins=8):\n",
    "    img = img//int(256/n_bins)\n",
    "    hist = np.bincount(img[:, :, 0].ravel(), minlength=8)\n",
    "    hist = np.append(hist, np.bincount(img[:, :, 1].ravel(), minlength=8))\n",
    "    hist = np.append(hist, np.bincount(img[:, :, 2].ravel(), minlength=8))\n",
    "    return hist\n",
    "\n",
    "\n",
    "def getHistForPatches(img, patch_shape):\n",
    "    patch_array = divideIntoPatches(img, patch_shape)\n",
    "    n, h, w, c = patch_array.shape\n",
    "    hist_array = np.empty((n, 24), dtype=np.int32)\n",
    "    for i in range(0, n):\n",
    "        hist_array[i] = getColorHistFeatures(patch_array[i])\n",
    "    return hist_array\n",
    "\n",
    "def loadImagesFromDir(dir_path):\n",
    "    images = {}\n",
    "    \n",
    "    for folder in os.listdir(dir_path):\n",
    "        img_arr = []\n",
    "        folder_path = dir_path + \"/\" + folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            img_path = folder_path + \"/\" + file\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img_arr.append(img)\n",
    "        images[folder] = img_arr\n",
    "    \n",
    "    return images\n",
    "\n",
    "def getHistForAllImages(images, patch_shape):\n",
    "    images_hist_features = {}\n",
    "\n",
    "    for key, img_arr in images.items():\n",
    "        hist24_arr = []\n",
    "        for img in img_arr:\n",
    "            hist24_arr.append(getHistForPatches(img, patch_shape))\n",
    "        images_hist_features[key] = hist24_arr\n",
    "    \n",
    "    return images_hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = loadImagesFromDir(\"Group21/Classification/Image_Group21/train\")\n",
    "test_images = loadImagesFromDir(\"Group21/Classification/Image_Group21/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_hist = getHistForAllImages(train_images, patch_shape=(32, 32))\n",
    "test_imgs_hist = getHistForAllImages(test_images, patch_shape=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_imgs_hist_flattened = np.concatenate([y for x in train_imgs_hist.values() for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(150752, 24)\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(train_imgs_hist_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# centroids = kmeans(train_imgs_hist_flattened, 32, 100)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=32, random_state=0).fit(train_imgs_hist_flattened)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  0  0 ... 28  6  6]\n[15515 11457  1963  5629  5314  3873  6691  4484  6180  1540 12314  5535\n  4195  4305  3462  2853  2409  3358  3170  6394  3538  1702  6742   748\n  1235  8638  5350  2095  3945  2815  1395  1908]\n39698874647.048\n76\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.labels_)\n",
    "print(np.bincount(kmeans.labels_))\n",
    "print(kmeans.inertia_)\n",
    "print(kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoVW_image_feature_vector(img_col_hist, centroids):\n",
    "    distances = cdist(img_col_hist, centroids ,'euclidean')\n",
    "    points = np.array([np.argmin(i) for i in distances])\n",
    "    feature = np.bincount(points, minlength=len(centroids))/points.shape[0]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,  11,  70,  23, 920,   0,   0,   0,   0,  13,\n",
       "        72,  20, 919,   0,   0,   0,   3,  49,  43,  36, 893])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "list(train_imgs_hist.values())[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.05769231 0.16346154 0.         0.         0.         0.\n 0.02884615 0.         0.00961538 0.03846154 0.15384615 0.00961538\n 0.04807692 0.         0.         0.05769231 0.         0.04807692\n 0.10576923 0.01923077 0.03846154 0.         0.11538462 0.\n 0.         0.06730769 0.         0.         0.         0.03846154\n 0.         0.        ]\n1.0\n"
     ]
    }
   ],
   "source": [
    "print(BoVW_image_feature_vector(list(train_imgs_hist.values())[0][0], centroids))\n",
    "print(BoVW_image_feature_vector(list(train_imgs_hist.values())[0][0], centroids).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_BoVW_train = {}\n",
    "for img_type, img_hist_array in train_imgs_hist.items():\n",
    "    img_BoVW = np.empty((len(img_hist_array), 32), dtype=np.float64)\n",
    "    for i in range(len(img_hist_array)):\n",
    "        img_BoVW[i] = BoVW_image_feature_vector(img_hist_array[i], centroids)\n",
    "    img_BoVW_train[img_type] = img_BoVW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_BoVW_test = {}\n",
    "for img_type, img_hist_array in test_imgs_hist.items():\n",
    "    img_BoVW = np.empty((len(img_hist_array), 32), dtype=np.float64)\n",
    "    for i in range(len(img_hist_array)):\n",
    "        img_BoVW[i] = BoVW_image_feature_vector(img_hist_array[i], centroids)\n",
    "    img_BoVW_test[img_type] = img_BoVW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32,)\n1.0\n"
     ]
    }
   ],
   "source": [
    "print(img_BoVW_train[\"batters_box\"][0].shape)\n",
    "print(img_BoVW_train[\"batters_box\"][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLFFNN_lib import MLFFNN\n",
    "\n",
    "c1 = img_BoVW_train['batters_box']\n",
    "c2 = img_BoVW_train['racecourse']\n",
    "c3 = img_BoVW_train['tree_farm']\n",
    "t1 = img_BoVW_test['batters_box']\n",
    "t2 = img_BoVW_test['racecourse']\n",
    "t3 = img_BoVW_test['tree_farm']\n",
    "\n",
    "\n",
    "c1 = np.append(c1, np.full((c1.shape[0], 3), [1, 0, 0]), axis=1)\n",
    "c2 = np.append(c2, np.full((c2.shape[0], 3), [0, 1, 0]), axis=1)\n",
    "c3 = np.append(c3, np.full((c3.shape[0], 3), [0, 0, 1]), axis=1)\n",
    "t1 = np.append(t1, np.full((t1.shape[0], 3), [1, 0, 0]), axis=1)\n",
    "t2 = np.append(t2, np.full((t2.shape[0], 3), [0, 1, 0]), axis=1)\n",
    "t3 = np.append(t3, np.full((t3.shape[0], 3), [0, 0, 1]), axis=1)\n",
    "data = np.concatenate((c1, c2, c3), axis=0)\n",
    "data1 = np.concatenate((t1, t2, t3), axis=0)\n",
    "np.random.shuffle(data)\n",
    "np.random.shuffle(data1)\n",
    "\n",
    "test_data = data\n",
    "train_data = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.025 , 0.    ,\n",
       "       0.    , 0.    , 0.075 , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "       0.    , 0.1875, 0.    , 0.2   , 0.375 , 0.    , 0.1375, 0.    ,\n",
       "       0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "       0.    , 0.    , 1.    ])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [[32, 20, 10, 3], [32, 40, 20, 3], [32, 64, 16, 3], [32, 64, 128, 16, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "***** network = [32, 20, 10, 3] *****\n\n\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (149,3) (149,3,1) ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-aca063f0605f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLFFNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"***** network = {layer_size} *****\\n\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"network = {layer_size}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\goyal\\OneDrive\\Desktop\\DL\\Deep-Learning-CS671\\Assignment1\\MLFFNN_lib.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_X, train_Y, test_X, test_Y, epochs, eta)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"=== Epoch {e+1}/{epochs} - Mean squared Error = {round(MSE, 4)} test accuracy = {round(test_accuracy*100, 4)}% ===\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\goyal\\OneDrive\\Desktop\\DL\\Deep-Learning-CS671\\Assignment1\\MLFFNN_lib.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# calculate mean squared error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mY_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetProbability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mY_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_predicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage_mean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\goyal\\OneDrive\\Desktop\\DL\\Deep-Learning-CS671\\Assignment1\\MLFFNN_lib.py\u001b[0m in \u001b[0;36maverage_mean_squared_error\u001b[1;34m(self, Y_actual, Y_predicted)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maverage_mean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0msquared_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_actual\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mmean_squared_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquared_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (149,3) (149,3,1) "
     ]
    }
   ],
   "source": [
    "for layer_size in layer_sizes:\n",
    "    net = MLFFNN(layers_size = layer_size)\n",
    "    print(f\"***** network = {layer_size} *****\\n\\n\")\n",
    "    net.train(train_data[:, :-3], train_data[:, 32:], test_data[:, :-3], test_data[:, 32:], epochs=5000, eta=.8)\n",
    "    plt.plot(net.MSE, label = f\"network = {layer_size}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Squared error\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}